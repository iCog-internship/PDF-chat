{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-together in ./venv/lib64/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in ./venv/lib64/python3.11/site-packages (from llama-index-embeddings-together) (0.11.9)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv/lib64/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.9.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.11.1)\n",
      "Requirement already satisfied: click in ./venv/lib64/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv/lib64/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib64/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib64/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in ./venv/lib64/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib64/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib64/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib64/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib64/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib64/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib64/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib64/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.22.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib64/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib64/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./venv/lib64/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib64/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib64/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (24.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-readers-file pymupdf\n",
    "%pip install llama-index-vector-stores-chroma\n",
    "%pip install llama-index-embeddings-together\n",
    "%pip install trulens-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key=os.getenv(\"TOEGETHER_API_KEY\")\n",
    "\n",
    "from llama_index.embeddings.together import TogetherEmbedding\n",
    "\n",
    "embed_model = TogetherEmbedding(\n",
    "    model_name=\"togethercomputer/m2-bert-80M-8k-retrieval\", api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import Settings\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.EphemeralClient()\n",
    "chroma_collection = chroma_client.create_collection(\"starter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "Doc ID: 0298c9c3-859d-4954-aaee-72e2967e5a62\n",
      "Text: Journal of Artiﬁcial General Intelligence 5(1) 1-46, 2014\n",
      "Submitted 2013-2-12 DOI: 10.2478/jagi-2014-0001 Accepted 2014-3-15\n",
      "Artiﬁcial General Intelligence: Concept, State of the Art, and Future\n",
      "Prospects Ben Goertzel BEN@GOERTZEL.ORG OpenCog Foundation G/F, 51C\n",
      "Lung Mei Village Tai Po, N.T., Hong Kong Editor: Tsvi Achler Abstract\n",
      "In recent year...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "\n",
    "loader = PyMuPDFReader()\n",
    "documents = loader.load(file_path=\"./data/AGI.pdf\")\n",
    "\n",
    "print(len(documents))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "text_splitter = SentenceSplitter(\n",
    "  separator=\" \",\n",
    "  chunk_size=1024,\n",
    "  chunk_overlap=20,\n",
    "  paragraph_separator=\"\\n\\n\\n\",\n",
    "  secondary_chunking_regex=\"[^,.;。]+[,.;。]?\",\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.cohere import Cohere\n",
    "load_dotenv()\n",
    "\n",
    "cohere_key=os.getenv(\"CO_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Cohere(api_key=cohere_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADHD, attention deficit hyperactivity disorder, is a complex mental health condition that can impact both children and adults. It is characterised by symptoms such as impaired concentration, hyperactivity and impulsivity. The latter can manifest physically, such as being unable to sit still for long periods, or mentally, with individuals finding it hard to focus on a single thought. \n",
      "\n",
      "While some individuals with ADHD may experience benefits from their symptoms, such as living an exciting and spontaneous life, the condition can also have negative effects. These can include low self-esteem, limited educational and employment opportunities, and comparisons to others, which can negatively impact an individual's confidence and potential.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)\n",
    "response = query_engine.query(\"What is adhd?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Window Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "# create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.node_parser = node_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index = VectorStoreIndex.from_documents(\n",
    "    [document], embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index.storage_context.persist(persist_dir=\"persist/sentence_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "postproc = MetadataReplacementPostProcessor(\n",
    "    target_metadata_key=\"window\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "from copy import deepcopy\n",
    "from llama_index.core import Document\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents([document])\n",
    "\n",
    "scored_nodes = [NodeWithScore(node=x, score=1.0) for x in nodes]\n",
    "nodes_old = [deepcopy(n) for n in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The impact of attention deﬁcit hyperactivity\\ndisorder (ADHD) in adulthood: a qualitative study\\nC. Watters1, D. Adamis2,*, F. McNicholas3 and B. Gavin3\\n1 Psychology Services, Markievicz House, HSE, Sligo, Ireland\\n2 Mental Health Services, HSE, Sligo, Ireland\\n3 Child and Adolescent Psychiatry, School of Medicine, UCD, Dublin, Ireland\\nObjectives. '"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_old[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADHD, or Attention Deficit Hyperactivity Disorder, is a complex mental health condition that often presents symptoms such as poor concentration, hyperactivity, and impulsivity. These symptoms can impact individuals' daily lives and functioning, leading to a sense of lost potential and low self-esteem. \n",
      "\n",
      "It is a disorder that can persist from childhood into adulthood, and adults with ADHD might experience challenges in various areas of their lives, including work and social situations.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "query_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    node_postprocessors=[\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "query = \"What is adhd?\"\n",
    "window_response = query_engine.query(\n",
    "    query\n",
    ")\n",
    "print(window_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer relevancy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "gen_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyDa4rFS5Y9BXRsxw5lBeF5XX2uopFvELv0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "from deepeval.test_case import LLMTestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_output = window_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = AnswerRelevancyMetric(\n",
    "    threshold=0.7,\n",
    "    model=\"gemini-1.5-flash \",\n",
    "    include_reason=True\n",
    ")\n",
    "\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What if these shoes don't fit?\",\n",
    "    actual_output=actual_output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto Merging Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "\n",
    "node_parser = HierarchicalNodeParser.from_defaults()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "\n",
    "\n",
    "root_nodes = get_root_nodes(nodes)\n",
    "\n",
    "len(leaf_nodes)\n",
    "len(root_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.docstore import SimpleDocumentStore \n",
    "from llama_index.core import StorageContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_index = VectorStoreIndex(\n",
    "    leaf_nodes,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import AutoMergingRetriever"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
