{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-together in ./venv/lib64/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in ./venv/lib64/python3.11/site-packages (from llama-index-embeddings-together) (0.11.9)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv/lib64/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.9.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv/lib64/python3.11/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib64/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.11.1)\n",
      "Requirement already satisfied: click in ./venv/lib64/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv/lib64/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib64/python3.11/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib64/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in ./venv/lib64/python3.11/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib64/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib64/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib64/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib64/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib64/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.1.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib64/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib64/python3.11/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (3.22.0)\n",
      "Requirement already satisfied: anyio in ./venv/lib64/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib64/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./venv/lib64/python3.11/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib64/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib64/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-together) (24.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-readers-file pymupdf\n",
    "%pip install llama-index-vector-stores-chroma\n",
    "%pip install llama-index-embeddings-together\n",
    "%pip install trulens-eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "api_key=os.getenv(\"TOEGETHER_API_KEY\")\n",
    "\n",
    "from llama_index.embeddings.together import TogetherEmbedding\n",
    "\n",
    "embed_model = TogetherEmbedding(\n",
    "    model_name=\"togethercomputer/m2-bert-80M-8k-retrieval\", api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from IPython.display import Markdown, display\n",
    "from llama_index.core import Settings\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.EphemeralClient()\n",
    "chroma_collection = chroma_client.create_collection(\"starter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "Doc ID: 0298c9c3-859d-4954-aaee-72e2967e5a62\n",
      "Text: Journal of Artiﬁcial General Intelligence 5(1) 1-46, 2014\n",
      "Submitted 2013-2-12 DOI: 10.2478/jagi-2014-0001 Accepted 2014-3-15\n",
      "Artiﬁcial General Intelligence: Concept, State of the Art, and Future\n",
      "Prospects Ben Goertzel BEN@GOERTZEL.ORG OpenCog Foundation G/F, 51C\n",
      "Lung Mei Village Tai Po, N.T., Hong Kong Editor: Tsvi Achler Abstract\n",
      "In recent year...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "\n",
    "loader = PyMuPDFReader()\n",
    "documents = loader.load(file_path=\"./data/AGI.pdf\")\n",
    "\n",
    "print(len(documents))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "text_splitter = SentenceSplitter(\n",
    "  separator=\" \",\n",
    "  chunk_size=1024,\n",
    "  chunk_overlap=20,\n",
    "  paragraph_separator=\"\\n\\n\\n\",\n",
    "  secondary_chunking_regex=\"[^,.;。]+[,.;。]?\",\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.cohere import Cohere\n",
    "load_dotenv()\n",
    "\n",
    "cohere_key=os.getenv(\"CO_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Cohere(api_key=cohere_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future of AGI (Artificial General Intelligence) is uncertain. Creating AGI systems that exhibit human-like general intelligence may require a revolutionary breakthrough or the gradual development of theory and experimentation. The progression of AGI research towards a more scientific and systematic approach is likely to yield more capable systems. However, the timeline and specifics of AGI's development are unclear. \n",
      "\n",
      "The current state of AGI research is such that ambitious goals, like those listed above, seem far off. The field relies heavily on the intuition and tinkering of researchers, and it's uncertain how much a more advanced AGI theory will impact practical system development. Still, progress in this direction is believed to benefit the AGI field overall, leading to more systematic and scientific design processes. \n",
      "\n",
      "The ultimate success of AGI will depend on various factors, some of which include the limitations of mathematics and computing, the potential for gradual theoretical development, and the role of human intuition in the design process.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)\n",
    "response = query_engine.query(\"WWhat is the future of AGI?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence Window Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "\n",
    "# create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.node_parser = node_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index = VectorStoreIndex.from_documents(\n",
    "    [document], embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index.storage_context.persist(persist_dir=\"persist/sentence_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "postproc = MetadataReplacementPostProcessor(\n",
    "    target_metadata_key=\"window\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "from copy import deepcopy\n",
    "from llama_index.core import Document\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents([document])\n",
    "\n",
    "scored_nodes = [NodeWithScore(node=x, score=1.0) for x in nodes]\n",
    "nodes_old = [deepcopy(n) for n in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Approaches to deﬁning the concept of Artiﬁcial\\nGeneral Intelligence (AGI) are reviewed including mathematical formalisms, engineering, and\\nbiology inspired perspectives. '"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_old[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_nodes = postproc.postprocess_nodes(scored_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text implies that AGI (Artificial General Intelligence) is being pursued as a way to create AI systems that can learn and think more like humans. AGI is positioned as a potential solution to the limitation of current AI technologies, which are narrow in scope and unable to generalize their learning to new situations. \n",
      "\n",
      "The development of AGI is framed as an emulation of the human learning environment, which could potentially enable machines to understand and tackle complex, interconnected real-world tasks. This would seemingly be a valuable tool for humans, especially when compared to the current state of AI, which is often task-specific and rigid in its application. \n",
      "\n",
      "The text also hints at the potential future usefulness of AGI technologies in making advancements in various fields, like robotics and human-AI interaction.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "query_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    node_postprocessors=[\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "query = \"Why do we need AGI?\"\n",
    "window_response = query_engine.query(\n",
    "    query\n",
    ")\n",
    "\n",
    "print(window_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer relevancy test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset \n",
    "from ragas.metrics import answer_relevancy\n",
    "from ragas import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = []\n",
    "for i in replaced_nodes:\n",
    "    context.append(i.text)\n",
    "\n",
    "data_samples = {\n",
    "    'question': ['What is AGI?', 'Why do we need AGI?'],\n",
    "    'answer': ['AGI stands for Artificial General Intelligence, which is a concept in artificial intelligence that refers to the development of machines that can perform any intellectual task that a human being can. AGI is also referred to as Strong AI or Human-Level AI.',\n",
    "'The text implies that AGI (Artificial General Intelligence) is being pursued as a way to create AI systems that can learn and think more like humans. AGI is positioned as a potential solution to the limitation of current AI technologies, which are narrow in scope and unable to generalize their learning to new situations. The development of AGI is motivated by the desire to create robots or computer programs that can handle the complexity and interconnectedness of real-world human tasks. Proponents of AGI research believe that this approach is a crucial step towards creating more flexible and adaptable AI systems. These systems would be able to recognize and respond to diverse situations, learning and developing new skills as needed. The ultimate goal, as implied by the text, is to create AI with a level of intelligence comparable to that of humans, which can then be applied to a host of challenges and problems that require more sophisticated and nuanced solutions than current AI technologies can provide.' ],  \n",
    "'contexts' : context\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto Merging Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import HierarchicalNodeParser\n",
    "\n",
    "node_parser = HierarchicalNodeParser.from_defaults()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "\n",
    "\n",
    "root_nodes = get_root_nodes(nodes)\n",
    "\n",
    "len(leaf_nodes)\n",
    "len(root_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.storage.docstore import SimpleDocumentStore \n",
    "from llama_index.core import StorageContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore = SimpleDocumentStore()\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_index = VectorStoreIndex(\n",
    "    leaf_nodes,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import AutoMergingRetriever"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
